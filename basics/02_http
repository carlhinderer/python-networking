-----------------------------------------------------------
CHAPTER 2 - HTTP
-----------------------------------------------------------

- Consuming Web Services with urllib

    - The 'urllib' module allows access to any resource published on a network through various protocols.
        To start consuming a web service, we have to import these libraries:

        >>> import urllib.request
        >>> import urllib.parse


    - There are 4 functions in urllib:

        1. request = opens and reads the request's URL
        2. error = contains the errors generated by the request
        3. parse = a tool to convert the URL
        4. robotparse = converts the 'robots.txt' file


    - The 'urllib.request' module allows access to a resource published on the internet through its
        address.  The main function that uses this module is 'urlopen'.  

      A 'urlopen' function is used to create an object similar to a file, with which to read from the URL.
        This object has methods like 'read', 'readLine', 'readLines', and 'close', which work exactly the
        same as file methods, although in reality we are using sockets.


    - The 'urlopen' function has an optional data parameter with which to send information to HTTP addresses
        using the 'POST' method.  This parameter is a properly encoded string:

        >>> urllib.request.urlopen (url, data = None, [timeout,] *, 
                                    cafile = None, capath = None, cadefault = False, context = None)



- Retrieving the Contents of a URL

    - Here, we retrieve the contents of a URL:

        >>> from urllib.request import urlopen

        # Send a request and receive a response (in this case an HTML page) from a resource
        >>> response = urlopen('http://www.packtpub.com')

        # Print the first line of the HTML page we received
        >>> response.readline()


    - The 'urlopen' function also supports specifying a timeout for the request that represents the
        waiting time in the request.  If the request takes longer than we indicated, it will result in 
        an error.  

        >>> print(urlopen('http://packtpub.com', timeout=30))


    - If we receive a JSON response, we can use the 'json' module to parse it.

        >>> import json
        >>> response = urlopen(url, timeout=30)
        >>> json_response = json.loads(response.read())



- HTTP Status Codes

    - We can get the HTTP response code with the 'status' attribute:

        >>> response.status
        200


    - Groups of response codes:

        100 = Informational
        200 = Success
        300 = Redirection
        400 = Client Error
        500 = Server Error



- Handling urllib Exceptions

    - Here, we'll request a nonexistent resource and handle the exception:

        >>> import urllib.error
        >>> from urllib.request import urlopen

        >>> try:
                urlopen('http://www.ietf.org/rfc/rfc0.txt')
            except urllib.error.HTTPError as e:
                print('Exception', e)
                print('status', e.code)
                print('reason', e.reason)
                print('url', e.url)



- HTTP Headers

    - HTTP requests consist of 2 main parts, a header and a body.  Headers are the lines of information
        that contain specific metadata about the response and tell the client how to interpret it.  With
        urllib, we can check the headers.


    - To inspect the headers from a response:

        >>> import urllib.request
        >>> http_response = urllib.request.urlopen(url)\

        # Print the header values
        >>> if http_response.code == 200:

                # Print all the headers
                print(http_response.headers)

                # Iterate through the headers
                for key, value in http_response.getheaders():
                    print(key, value)